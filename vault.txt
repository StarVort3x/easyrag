

## Sheet1

| 周次 | 星期 | 节次 | 课程名称 | 实验项目名称 | 实验课时数 | 实验类型 | 班级 | 班级人数 | 二级实验室名称 | 实验地点门牌号 |
| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |
| 2.0 | 1.0 | 5~7 | 数据结构 | 顺序表的基本操作 | 3.0 | 验证型 | 数据科学181 | 24.0 | 基础实验室 | 11-505 |
| 4.0 | 1.0 | 5~7 | 数据结构 | 链表的基本操作 | 3.0 | 验证型 | 数据科学181 | 24.0 | 基础实验室 | 11-505 |
| 6.0 | 1.0 | 5~7 | 数据结构 | 栈的基本运算 | 3.0 | 验证型 | 数据科学181 | 24.0 | 基础实验室 | 11-505 |
| 8.0 | 1.0 | 5~7 | 数据结构 | 二叉树的操作 | 3.0 | 验证型 | 数据科学181 | 24.0 | 基础实验室 | 11-505 |
| 10.0 | 1.0 | 5~7 | 数据结构 | 马踏棋盘问题 | 3.0 | 验证型 | 数据科学181 | 24.0 | 基础实验室 | 11-505 |
| 12.0 | 1.0 | 5~7 | 数据结构 | 二叉检索树 | 3.0 | 验证型 | 数据科学181 | 24.0 | 基础实验室 | 11-505 |
| 14.0 | 1.0 |  | 数据结构 | 排序与查找 | 3.0 | 验证型 | 数据科学181 | 24.0 | 基础实验室 | 11-505 |
| 16.0 | 1.0 | 5~7 | 数据结构 | 图的操作 | 3.0 | 验证型 | 数据科学181 | 24.0 | 基础实验室 | 11-505 |
| 1.0 | 4.0 | 7~8 | 数据挖掘与机器学习 | 机器学习案例：大豆分类 | 2.0 | 验证型 | 数据科学(卓越)171 | 30.0 | 人工智能实验室 | 11-305 |
| 2.0 | 4.0 | 7~8 | 数据挖掘与机器学习 | 树、规则 | 2.0 | 验证型 | 数据科学(卓越)171 | 30.0 | 人工智能实验室 | 11-305 |
| 3.0 | 4.0 | 7~8 | 数据挖掘与机器学习 | 最佳回归系数 | 2.0 | 验证型 | 数据科学(卓越)171 | 30.0 |  |  |
| 4.0 | 4.0 | 7~8 | 数据挖掘与机器学习 | 构造决策树 | 2.0 | 验证型 | 数据科学(卓越)171 | 30.0 | 人工智能实验室 | 11-305 |
| 5.0 | 4.0 | 7~8 | 数据挖掘与机器学习 | 文本分类 | 2.0 | 设计型 | 数据科学(卓越)171 | 30.0 | 人工智能实验室 | 11-305 |
| 6.0 | 4.0 | 7~8 | 数据挖掘与机器学习 | 距离及相似度 | 2.0 | 验证型 | 数据科学(卓越)171 | 30.0 | 人工智能实验室 | 11-305 |
| 7.0 | 4.0 | 7~8 | 数据挖掘与机器学习 | 最大间隔 | 2.0 | 验证型 | 数据科学(卓越)171 | 30.0 | 人工智能实验室 | 11-305 |
| 8.0 | 4.0 | 7~8 | 数据挖掘与机器学习 | RNN、CNN | 2.0 | 验证型 | 数据科学(卓越)171 | 30.0 | 人工智能实验室 | 11-305 |
| 9.0 | 4.0 | 7~8 | 数据挖掘与机器学习 | RNN、CNN应用 | 2.0 | 设计型 | 数据科学(卓越)171 | 30.0 | 人工智能实验室 | 11-305 |
| 10.0 | 4.0 | 7~8 | 数据挖掘与机器学习 | 多维回归 | 2.0 | 验证型 | 数据科学(卓越)171 | 30.0 | 人工智能实验室 | 11-305 |
| 11.0 | 4.0 | 7~8 | 数据挖掘与机器学习 | 交叉验证 | 2.0 | 验证型 | 数据科学(卓越)171 | 30.0 | 人工智能实验室 | 11-305 |
| 12.0 | 4.0 | 7~8 | 数据挖掘与机器学习 | 特征降维 | 2.0 | 验证型 | 数据科学(卓越)171 | 30.0 | 人工智能实验室 | 11-305 |
| 13.0 | 4.0 | 7~8 | 数据挖掘与机器学习 | 召回率、成本曲线 | 2.0 | 设计型 | 数据科学(卓越)171 | 30.0 | 人工智能实验室 | 11-305 |
| 14.0 | 4.0 | 7~8 | 数据挖掘与机器学习 | 分级聚类 | 2.0 | 设计型 | 数据科学(卓越)171 | 30.0 | 人工智能实验室 | 11-305 |
| 15.0 | 4.0 | 7~8 | 数据挖掘与机器学习 | K-均值聚类 | 2.0 | 设计型 | 数据科学(卓越)171 | 30.0 | 人工智能实验室 | 11-305 |
| 16.0 | 4.0 | 7~8 | 数据挖掘与机器学习 | 聚集输入与输出 | 2.0 | 综合型 | 数据科学(卓越)171 | 30.0 | 人工智能实验室 | 11-305 |
| 9.0 | 1.0 | 7~9 | 数据科学导论 | Python基础与Anocanda | 3.0 | 验证型 | 数据科学182 | 32.0 | 数据科学实验室 | 11-309 |
| 10.0 | 1.0 | 7~9 | 数据科学导论 | 多维数组使用 | 3.0 | 验证型 | 数据科学182 | 32.0 | 数据科学实验室 | 11-309 |
| 11.0 | 1.0 | 7~9 | 数据科学导论 | Pandas数据操作 | 3.0 | 验证型 | 数据科学182 | 32.0 | 数据科学实验室 | 11-309 |
| 12.0 | 1.0 | 7~9 | 数据科学导论 | Pandas数据统计 | 3.0 | 验证型 | 数据科学182 | 32.0 | 数据科学实验室 | 11-309 |
| 13.0 | 1.0 | 7~9 | 数据科学导论 | Pandas数据规整 | 3.0 | 设计型 | 数据科学182 | 32.0 | 数据科学实验室 | 11-309 |
| 14.0 | 1.0 | 7~9 | 数据科学导论 | 可视化分析 | 3.0 | 设计型 | 数据科学182 | 32.0 | 数据科学实验室 | 11-309 |
| 15.0 | 1.0 | 7~9 | 数据科学导论 | 综合应用设计 | 3.0 | 综合型 | 数据科学182 | 32.0 | 数据科学实验室 | 11-309 |
| 16.0 | 1.0 | 7~9 |  | 综合应用设计 | 3.0 | 综合型 | 数据科学182 | 32.0 | 数据科学实验室 | 11-309 |
| 1.0 | 2.0 | 1-4 | Python语言程序设计 | 认识Python | 4.0 | 验证型 | 数据科学（卓越）191 | 30.0 | 基础实验室 | 11-505 |
| 2.0 | 2.0 | 1-4 | Python语言程序设计 | Python数据结构 | 4.0 | 验证型 | 数据科学（卓越）191 | 30.0 | 基础实验室 | 11-505 |
| 3.0 | 2.0 | 1-4 | Python语言程序设计 | 选择与循环 | 4.0 | 验证型 | 数据科学（卓越）191 | 30.0 | 基础实验室 | 11-505 |
| 4.0 | 2.0 | 1-4 | Python语言程序设计 | 字符串使用 | 4.0 | 验证型 | 数据科学（卓越）191 | 30.0 | 基础实验室 | 11-505 |
| 5.0 | 2.0 | 1-4 | Python语言程序设计 | 函数与类设计 | 4.0 | 验证型 | 数据科学（卓越）191 | 30.0 | 基础实验室 | 11-505 |
| 6.0 | 2.0 | 1-4 | Python语言程序设计 | 文件操作与异常处理 | 4.0 | 验证型 | 数据科学（卓越）191 | 30.0 | 基础实验室 | 11-505 |
| 7.0 | 2.0 | 1-4 | Python语言程序设计 | 界面设计 | 4.0 | 验证型 | 数据科学（卓越）191 | 30.0 | 基础实验室 | 11-505 |
| 8.0 | 2.0 | 1-4 | Python语言程序设计 | 综合程序设计 | 4.0 | 综合型 | 数据科学（卓越）191 | 30.0 | 基础实验室 | 11-505 |
|  |  |  |  |  |  |  |  |  |  |  |
| 1.0 | 4.0 | 3～4 | 大数据技术 | Hadoop安装与HDFS使用 | 2.0 | 验证型 | 大数据应用171 | 38.0 | 数据科学实验室 | 11-309 |
| 2.0 | 4.0 | 3～4 | 大数据技术 | MapReduce编程基础 | 2.0 | 验证型 | 大数据应用171 | 38.0 | 数据科学实验室 | 11-309 |
| 3.0 | 4.0 | 3～4 | 大数据技术 | HBase的使用 | 2.0 | 验证型 | 大数据应用171 | 38.0 | 数据科学实验室 | 11-309 |
| 4.0 | 4.0 | 3～4 | 大数据技术 | Hive的使用 | 2.0 | 验证型 | 大数据应用171 | 38.0 | 数据科学实验室 | 11-309 |
| 5.0 | 4.0 | 3～4 | 大数据技术 | MapReduce并行编程应用 | 2.0 | 设计型 | 大数据应用171 | 38.0 | 数据科学实验室 | 11-309 |
| 6.0 | 4.0 | 3～4 | 大数据技术 | 并行聚类和分类算法 | 2.0 | 设计型 | 大数据应用171 | 38.0 | 数据科学实验室 | 11-309 |
| 7.0 | 4.0 | 3～4 | 大数据技术 | 并行聚类和分类算法 | 2.0 | 设计型 | 大数据应用171 | 38.0 | 数据科学实验室 | 11-309 |
| 8.0 | 4.0 | 3～4 | 大数据技术 | 频繁项挖掘和马尔科夫链 | 2.0 | 验证型 | 大数据应用171 | 38.0 | 数据科学实验室 | 11-309 |
| 9.0 | 4.0 | 3～4 | 大数据技术 | Spark和流处理Streaming | 2.0 | 设计型 | 大数据应用171 | 38.0 | 数据科学实验室 | 11-309 |
| 10.0 | 4.0 | 3～4 | 大数据技术 | Spark和流处理Streaming | 2.0 | 设计型 | 大数据应用171 | 38.0 | 数据科学实验室 | 11-309 |
| 11.0 | 4.0 | 3～4 | 大数据技术 | 数据挖掘MLlib、图处理GraphX | 2.0 | 验证型 | 大数据应用171 | 38.0 | 数据科学实验室 | 11-309 |
| 12.0 | 4.0 | 3～4 | 大数据技术 | Tableau数据可视化 | 2.0 | 设计型 | 大数据应用171 | 38.0 | 数据科学实验室 | 11-309 |
| 13.0 | 4.0 | 3～4 | 大数据技术 | Tableau数据可视化 | 2.0 | 设计型 | 大数据应用171 | 38.0 | 数据科学实验室 | 11-309 |
| 14.0 | 4.0 | 3～4 | 大数据技术 | 大数据处理应用实现 | 2.0 | 综合型 | 大数据应用171 | 38.0 | 数据科学实验室 | 11-309 |
| 15.0 | 4.0 | 3～4 | 大数据技术 | 大数据处理应用实现 | 2.0 | 综合型 | 大数据应用171 | 38.0 | 数据科学实验室 | 11-309 |
| 16.0 | 4.0 | 3～4 | 大数据技术 | 大数据处理应用实现 | 2.0 | 综合型 | 大数据应用171 | 38.0 | 数据科学实验室 | 11-309 |
| 9.0 | 5.0 | 1～4 | 商务数据分析 | Anaconda环境与Python编程 | 4.0 | 实训 | 数据科学171 | 25.0 | 数据科学实验室 | 11-309 |
| 11.0 | 5.0 | 1～4 | 商务数据分析 | 电子商务指标体系统计实现 | 4.0 | 实训 | 数据科学171 | 25.0 | 数据科学实验室 | 11-309 |
| 12.0 | 5.0 | 1～4 | 商务数据分析 | 客户价值分析实现 | 4.0 | 实训 | 数据科学171 | 25.0 | 数据科学实验室 | 11-309 |
| 13.0 | 5.0 | 1～4 | 商务数据分析 | 北京商品房定价分析 | 4.0 | 实训 | 数据科学171 | 25.0 | 数据科学实验室 | 11-309 |
| 14.0 | 5.0 | 1～4 | 商务数据分析 | 股票价格趋势分析 | 4.0 | 实训 | 数据科学171 | 25.0 | 数据科学实验室 | 11-309 |
| 15.0 | 5.0 | 1～4 | 商务数据分析 | 用户行为幂律分析 | 4.0 | 实训 | 数据科学171 | 25.0 | 数据科学实验室 | 11-309 |
| 9.0 | 4.0 | 7～9 | 数据科学导论 | Python基础与Anocanda | 3.0 | 验证型 | 数据科学182 | 32.0 | 数据科学实验室 | 11-309 |
| 10.0 | 4.0 | 7～9 | 数据科学导论 | 多维数组使用 | 3.0 | 验证型 | 数据科学182 | 32.0 | 数据科学实验室 | 11-309 |
| 11.0 | 4.0 | 7～9 | 数据科学导论 | Pandas数据操作 | 3.0 | 验证型 | 数据科学182 | 32.0 | 数据科学实验室 | 11-309 |
| 12.0 |  | 7～9 | 数据科学导论 | Pandas数据统计 | 3.0 | 验证型 | 数据科学182 | 32.0 | 数据科学实验室 | 11-309 |
| 13.0 | 4.0 | 7～9 | 数据科学导论 | Pandas数据规整 | 3.0 | 设计型 | 数据科学182 | 32.0 | 数据科学实验室 | 11-309 |
| 14.0 | 4.0 | 7～9 | 数据科学导论 | 可视化分析 | 3.0 |  | 数据科学182 | 32.0 | 数据科学实验室 | 11-309 |
| 15.0 | 4.0 | 7～9 | 数据科学导论 | 综合应用设计 | 3.0 | 综合型 | 数据科学182 | 32.0 | 数据科学实验室 | 11-309 |
| 16.0 | 4.0 | 7～9 | 数据科学导论 | 综合应用设计 | 3.0 | 综合型 | 数据科学182 | 32.0 | 数据科学实验室 | 11-309 |
| 1.0 | 3.0 | 7~8 | 数据挖掘与机器学习 | 机器学习案例：大豆分类 | 2.0 | 验证型 | 数据科学172 | 30.0 | 人工智能实验室 | 11-305 |
| 2.0 | 3.0 | 7~8 | 数据挖掘与机器学习 | 树、规则 | 2.0 | 验证型 | 大数据应用171 | 25.0 | 人工智能实验室 | 11-305 |
| 3.0 | 3.0 | 7~8 | 数据挖掘与机器学习 | 最佳回归系数 | 2.0 | 验证型 | 大数据应用171 | 25.0 | 人工智能实验室 | 11-305 |
| 4.0 | 3.0 | 7~8 | 数据挖掘与机器学习 | 构造决策树 | 2.0 | 验证型 | 大数据应用171 | 25.0 | 人工智能实验室 | 11-305 |
| 5.0 | 3.0 | 7~8 | 数据挖掘与机器学习 | 文本分类 | 2.0 | 设计型 | 大数据应用171 | 25.0 | 人工智能实验室 | 11-305 |
| 6.0 | 3.0 | 7~8 | 数据挖掘与机器学习 | 距离及相似度 | 2.0 | 验证型 | 大数据应用171 | 25.0 | 人工智能实验室 | 11-305 |
| 7.0 | 3.0 | 7~8 | 数据挖掘与机器学习 | 最大间隔 | 2.0 | 验证型 | 大数据应用171 | 25.0 | 人工智能实验室 | 11-305 |
| 8.0 | 3.0 | 7~8 | 数据挖掘与机器学习 | RNN、CNN | 2.0 | 验证型 | 大数据应用171 | 25.0 | 人工智能实验室 | 11-305 |
| 9.0 | 3.0 | 7~8 | 数据挖掘与机器学习 | RNN、CNN应用 | 2.0 | 设计型 | 大数据应用171 | 25.0 | 人工智能实验室 | 11-305 |
| 10.0 | 3.0 | 7~8 | 数据挖掘与机器学习 | 多维回归 | 2.0 | 验证型 | 大数据应用171 | 25.0 | 人工智能实验室 | 11-305 |
| 11.0 | 3.0 | 7~8 | 数据挖掘与机器学习 | 交叉验证 | 2.0 | 验证型 | 大数据应用171 | 25.0 | 人工智能实验室 | 11-305 |
| 12.0 | 3.0 | 7~8 | 数据挖掘与机器学习 | 特征降维 | 2.0 | 验证型 | 大数据应用171 | 25.0 | 人工智能实验室 | 11-305 |
| 13.0 | 3.0 | 7~8 | 数据挖掘与机器学习 | 召回率、成本曲线 | 2.0 | 设计型 | 大数据应用171 | 25.0 | 人工智能实验室 | 11-305 |
| 14.0 | 3.0 | 7~8 | 数据挖掘与机器学习 | 分级聚类 | 2.0 | 设计型 | 大数据应用171 | 25.0 | 人工智能实验室 | 11-305 |
| 15.0 | 3.0 | 7~8 | 数据挖掘与机器学习 | K-均值聚类 | 2.0 | 设计型 | 大数据应用171 | 25.0 | 人工智能实验室 | 11-305 |
| 16.0 | 3.0 | 7~8 | 数据挖掘与机器学习 | 聚集输入与输出 | 2.0 | 综合型 | 大数据应用171 | 25.0 | 人工智能实验室 | 11-305 |
|  |  |  |  |  |  |  |  |  |  |  |
| 1.0 | 3.0 | 5-8 | Python语言程序设计 | 认识Python | 4.0 | 验证型 | 大数据应用191 | 34.0 | 基础实验室 | 11-505 |
| 2.0 | 3.0 | 5-8 | Python语言程序设计 | Python数据结构 | 4.0 | 验证型 | 大数据应用191 | 34.0 | 基础实验室 | 11-505 |
| 3.0 | 3.0 | 5-8 | Python语言程序设计 | 选择与循环 | 4.0 | 验证型 | 大数据应用191 | 34.0 | 基础实验室 | 11-505 |
| 4.0 | 3.0 | 5-8 | Python语言程序设计 | 字符串使用 | 4.0 | 验证型 | 大数据应用191 | 34.0 | 基础实验室 | 11-505 |
| 5.0 | 3.0 | 5-8 | Python语言程序设计 | 函数与类设计 | 4.0 | 验证型 | 大数据应用191 | 34.0 | 基础实验室 | 11-505 |
| 6.0 | 3.0 | 5-8 | Python语言程序设计 | 文件操作与异常处理 | 4.0 | 验证型 | 大数据应用191 | 34.0 | 基础实验室 | 11-505 |
| 7.0 | 3.0 | 5-8 | Python语言程序设计 | 界面设计 | 4.0 | 验证型 | 大数据应用191 | 34.0 | 基础实验室 | 11-505 |
| 8.0 | 3.0 | 5-8 | Python语言程序设计 | 综合程序设计 | 4.0 | 综合型 | 大数据应用191 | 34.0 | 基础实验室 | 11-505 |

## 非织造

|  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |
| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |
| 周次 | 星期 | 节次 | 课程名称 | 实验项目名称 | 实验课时数 | 实验类型 | 班级 | 班级人数 | 批数 | 每批组数 | 每组人数 | 二级实验室名称 | 实验地点门牌号 | 指导教师 |
| 9.0 | 1.0 | 5~8 | 非织造概论 | 短纤维成网工艺和原理 | 4.0 | 综合性 | 纺织151 | 25.0 | 2.0 | 8.0 | 3~4 | 纺织实验室 | 12号楼121室 | 钱程/张彩丹 |
| 9.0 | 2.0 | 1~4 | 非织造学Ⅰ | 干法成网前准备实验 | 4.0 | 综合性 | 非织造151(非织造产品设计) | 21.0 | 2.0 | 7.0 | 3.0 | 纺织实验室 | 12号楼121室 | 钱程/方瑞峰 |
| 9.0 | 2.0 | 5~8 | 非织造学Ⅰ | 干法成网前准备实验 | 4.0 | 综合性 | 非织造151(非织造产品设计) | 21.0 | 2.0 | 7.0 | 3.0 | 纺织实验室 | 12号楼121室 | 钱程/方瑞峰 |
| 9.0 | 3.0 | 5~8 | 非织造概论 | 短纤维成网工艺和原理 | 4.0 | 综合性 | 纺织151 | 25.0 | 2.0 | 8.0 | 3~4 | 纺织实验室 | 12号楼121室 | 钱程/张彩丹 |
| 10.0 | 1.0 | 5~6 | 非织造学Ⅰ | 交叉铺网实验 | 2.0 | 综合性 | 非织造151(非织造产品设计) | 21.0 | 2.0 | 7.0 | 3.0 | 纺织实验室 | 12号楼121室 | 钱程/方瑞峰 |
| 10.0 | 2.0 | 1~4 | 非织造学Ⅰ | 湿法非织造布成网实验 | 4.0 | 综合性 | 非织造151(非织造产品设计) | 21.0 | 2.0 | 7.0 | 3.0 | 纺织实验室 | 12号楼121室 | 钱程/方瑞峰 |
| 10.0 | 3.0 | 5~8 | 非织造学Ⅰ | 湿法非织造布成网实验 | 4.0 | 综合性 | 非织造151(非织造产品设计) | 21.0 | 2.0 | 7.0 | 3.0 | 纺织实验室 | 12号楼121室 | 钱程/方瑞峰 |
| 10.0 | 5.0 | 3~4 | 非织造学Ⅰ | 交叉铺网实验 | 2.0 | 综合性 | 非织造151(非织造产品设计) | 21.0 | 2.0 | 7.0 | 3.0 | 纺织实验室 | 12号楼121室 | 钱程/方瑞峰 |
| 11.0 | 1.0 | 5~6 | 非织造学Ⅰ | 热轧非织造布成形实验 | 2.0 | 综合性 | 非织造151(非织造产品设计) | 21.0 | 2.0 | 7.0 | 3.0 | 纺织实验室 | 12号楼121室 | 钱程/方瑞峰 |
| 11.0 | 2.0 | 1~4 | 非织造学Ⅰ | 针刺非织造布成形实验 | 4.0 | 综合性 | 非织造151(非织造产品设计) | 21.0 | 2.0 | 7.0 | 3.0 | 纺织实验室 | 12号楼121室 | 钱程/方瑞峰 |
| 11.0 | 2.0 | 5~8 | 非织造学Ⅰ | 针刺非织造布成形实验 | 4.0 | 综合性 | 非织造151(非织造产品设计) | 21.0 | 2.0 | 7.0 | 3.0 | 纺织实验室 | 12号楼121室 | 钱程/方瑞峰 |
| 11.0 | 5.0 | 5~6 | 非织造学Ⅰ | 热轧非织造布成形实验 | 2.0 | 综合性 | 非织造151(非织造产品设计) | 21.0 | 2.0 | 7.0 | 3.0 | 纺织实验室 | 12号楼121室 | 钱程/方瑞峰 |
| 12.0 | 2.0 | 1~4 | 土工合成材料与应用 | 土工合成材料的耐静水压测试 | 4.0 | 验证性 | 非织造151(非织造产品设计) | 21.0 | 2.0 | 10.0 | 2~3 | 纺织实验室 | 11号楼405室 | 许志/李喆 |
| 12.0 | 3.0 | 5~8 | 土工合成材料与应用 | 土工合成材料的耐静水压测试 | 4.0 | 验证性 | 非织造151(非织造产品设计) | 21.0 | 2.0 | 10.0 | 2~3 | 纺织实验室 | 11号楼405室 | 许志/李喆 |
| 13.0 | 2.0 | 1~4 | 土工合成材料与应用 | 土工合成材料的垂直渗透性能测试 | 4.0 | 验证性 | 非织造151(非织造产品设计) | 21.0 | 2.0 | 11.0 | 2.0 | 纺织实验室 | 11号楼405室 | 许志/李喆 |
| 13.0 | 3.0 | 5~8 | 土工合成材料与应用 | 土工合成材料的垂直渗透性能测试 | 4.0 | 验证性 | 非织造151(非织造产品设计) | 21.0 | 2.0 | 11.0 | 2.0 | 纺织实验室 | 11号楼405室 | 许志/李喆 |



## Numpy

|  | 引用模块 | 函数/属性名 | 实例 | 说明 |  |
| --- | --- | --- | --- | --- | --- |
|  | import numpy as np |  |  |  |  |
|  | 1）基本属性 |  |  |  |  |
|  |  | array.ndim |  | 数组维度 |  |
|  |  | array.size |  | 数组元素个数 |  |
|  |  | array.dtype |  | 数组数据类型 |  |
|  |  |  |  |  |  |
|  | 2) 基本函数 |  |  |  |  |
|  |  | np.set_printoptions() | np.set_printoptions(precision=4, suppress=True) | 设置输出精度，是否使用科学计算 |  |
|  |  | np.array() | np.array([[1,2,3,4],[0,1,2,3]] ) | 创建 ndarray对象 |  |
|  |  | np.arange() | np.arange(15)<br>np.arrange(-3,3,0.2)  #0.2为步长 | 创建一个等差数组 |  |
|  |  | np.zeros() | np.zeros(10)<br>np.zeros( (3,6) ) | 生成一个给定大小的全0数组 |  |
|  |  | np.ones() | np.ones( (2,3,2) ） | 生成一个给定大小的全1数组 |  |
|  |  | np.reshape() | np.arange(15).reshape(3, 5) | 将一维数组转换为指定的多维数组 |  |
|  |  |  |  |  |  |
|  | 3) 通用数学函数 |  |  |  |  |
|  |  | np.abs()、np.fabs() | np.abs(x)，np.fabs(x) | 计算整数、浮点数或复数的绝对值 |  |
|  |  | np.sqrt() | np.sqrt(arr) | 计算各元素的平方根 |  |
|  |  | np.square() | np.square(x) | 计算各元素的平方 |  |
|  |  | np.exp() | np.exp(arr) | 计算各元素的指数 |  |
|  |  | np.sin()、np.cos()、np.cosh()、np.sin() <br>np.sinh()、np.tan()、np.tanh() | np.sin(arr) | 普通和双曲型三角函数 |  |
|  |  | np.floor() | np.floor(arr/10) #将arr转换成整数形式的十分制分数 | 计算各元素的floor值，即小于等于该值的最大整数 |  |
|  |  | np.ceil() |  | 计算各元素的ceiling值，即大于等于该值的最小整数 |  |
|  |  |  |  |  |  |
|  | 3) 二元函数 |  |  |  |  |
|  |  | np.add() |  | 将数据中对应的元素相加 |  |
|  |  | np.subtract() |  | 从第一个数组中减去第二个数组中的元素 |  |
|  |  | np.multiply() |  | 数组元素相乘 |  |
|  |  | np.divide() |  | 除法或向下取整除法 |  |
|  |  | np.power() |  | 对第一个数组中的元素A，根据第二个数组中的相应元素B，计算AB |  |
|  |  | np.mod() |  | 元素级的求模运算 |  |
|  |  | np.copysign() |  | 将第二个数组中的值的符号复制给第一个数组中的值 |  |
|  |  | np.equal(),np.not_equal() |  | 执行元素级的比较运算，产生布尔型数组 |  |
|  |  |  |  |  |  |
|  | 4) 聚集函数 |  |  |  |  |
|  |  | array.sum() | arr.sum() #全部求和<br>arr.sum(1) #按给定轴求和，产生低一维的数组 | 求和函数 |  |
|  |  | array.mean() | arr.mean() | 算术平均值 |  |
|  |  | array.min()、array.max() | arr.max()、arr.min() | 最大值和最小值 |  |
|  |  | array.argmin()、array.argmax() | arr.argmax()、arr.argmin() | 最大值和最小值的索引 |  |
|  |  | array.cumsum() | arr.cumsum(axis = 1)  #逐列求累加和 | 从0开始向前累加各元素 |  |
|  |  | array.cumprod() | arr.cumprod() | 从1开始向前累乘各元素 |  |
|  |  |  |  |  |  |
|  | 5) 随机生成函数 |  |  |  |  |
|  |  | np.random.random() |  | 随机产生[0,1)之间的浮点值 |  |
|  |  | np.random.randint() | np.random.randint(0, 2, size = (2,10)) #生成0-1之间的整数随机数，维度是2*10 | 随机生成给定范围内的一组整数 |  |
|  |  | np.random.uniform() |  | 随机生成给定范围内服从均匀分布的一组浮点数 |  |
|  |  | np.random.choice() |  | 在给定的序列内随机选择元素 |  |
|  |  | np.random.normal() | np.random.normal( 1, 2.1, size(4,4) ) #生成4*4的矩阵，均值为1，方差为2.1 | 随机生成一组服从给定均值和方差的正态分布随机数 |  |
|  |  |  |  |  |  |
|  | 6) 条件逻辑的数组运算 |  |  |  |  |
|  |  | np.where() | result = np.where(cond, xarr, yarr)<br>np.where( arr>0, 2, -2)   #将arr数组中>0的替换为2，其余替换为-2<br>np.where( arr>0, 2, arr)   #将arr数组中>0的替换为2，其余不变 | 三元表达式：x if condition else y的矢量化版本 |  |

## pandas

|  | 引用模块 | 函数/属性名 | 实例 | 说明 |
| --- | --- | --- | --- | --- |
|  | import pandas as pd |  |  |  |
|  | 1) pandas数据结构 |  |  |  |
|  |  | Series() | obj1=Series([4,7,5,3],index=['d','b','a','c'])   #创建带索引的Series<br>states=['California','Ohio','Oregon']    #使用字典创建Series<br>obj3=Series(sdata,index=states) | 创建Series |
|  |  | Series() |  |  |
|  |  | DataFrame() | frame2=([1,2,3,],[4,5,6],columns=['a','b','c'],index=['x','y']) | 创建DataFrame |
|  | 基于索引名选取 | obj[ col ] |  | 选取某列 |
|  |  | obj[ colList ] | students[['height','weight']] | 选取某几列 |
|  |  | obj.loc[ index, col ] |  | 选取某行某列 |
|  |  | obj.loc[ indexList, colList ] |  | 选取多行多列 |
|  | 基于位置序号选取 | obj.iloc[ iloc, cloc] |  | 选取某行某列 |
|  |  | obj.iloc[ ilocList, clocList ] |  | 选取多行多列 |
|  |  | obj.iloc[ a:b, c:d ] | students.iloc[1:, 0:2] | 选取a~(b-1)行, c~(d-1)列 |
|  | 条件筛选 | obj.loc[ condition, colList ] | students.loc[ students['height']>=168, ['height','weight'] ] | 使用索引构造条件表达式，选取满足条件的行 |
|  |  | obj.iloc[ condition, clocList ] |  | 使用位置序号构造条件表达式，选取满足条件的行 |
|  |  | obj[colname] = list | students['expense'] = [1500,1600,1200] | 添加新列 |
|  |  | obj.drop(collist, axis, inplace,...) | students.drop(1, axis=0)<br>students.drop('expense', axis=1) | 删除某几列 |
|  |  |  |  |  |
|  | 2) 数据文件读写 |  |  |  |
|  |  | pd.read_csv() | pd.read_csv('1111.csv') | 读取CSV文件数据（带分隔符的数据,默认为逗号） |
|  |  | object.to_csv() | ts = Series(np.arange(7), index=dates) <br>ts.to_csv('ch06/tseries.csv') | 将DataFrame或Series中的数据写到一个以逗号分隔的文件中 |
|  |  | pd.read_excel() | pd.read_excel('a.xlsx', 'Group1') | 从excel文件的指定表单中读取数据 |
|  | 参数 | sep | sep=‘，’ | 字符串，每行各数据之间的分隔符 |
|  |  | header | header = None | 文件中第一行不是列索引，默认第一行为列索引 |
|  |  | index_col | index_col = 0 | 用作行索引的列序号 |
|  |  | names | names=['学号'，‘成绩’] | 列表，定义列索引，如果不使用文件中第一行为列索引 |
|  |  | skiprows | pd.read_csv('ch06/ex4.csv', skiprows=[0, 2, 3]) #跳过文件的第一行、第三行和第四行 | 跳过文件中的某些行 |
|  |  | na_values | pd.read_csv('ch06/ex5.csv' ,na_values=['NULL']) | 可以接受一组用于表示缺失值的字符串 |
|  |  | nrows | pd.read_csv('ch06/ex6.csv' , nrows=5)  #nrows=5表示读取前5行 | 逐行读取文本文件 |
|  |  | delimiter | reader = csv.reader(f, delimiter= '\|') | 用于分隔字段的单字符字符串。默认',' |
|  |  |  |  |  |
|  | 3) 数据清洗 |  |  |  |
|  |  | dataframe.dropna() | data1.dropna(thresh=3)  #thresh代表保留几个有效值 | 滤除缺失数据 |
|  |  | dataframe.fillna(value, method, inplace, ...) | df1.fillna(0)<br>stu.fillna({'年龄':20, '体重':stu['体重'].mean()} )<br>method='ffill'    method='bfill' | 填充缺失数据 |
|  |  | dataframe.drop_duplicates() | df1.drop_duplicates() | 去除重复数据 |
|  |  | dataframe.isnull() | stu.isnull() | 检测每个元素值是否是NaN |
|  |  | dataframe.any() | stu.isnull().any() | 按行或列检测是否有值为Flase |
|  | 参数 | inplace | True , False | 是否替换原数据,默认为False |
|  |  |  |  |  |
|  | 4) 数据规整化 |  |  |  |
|  |  | pd.concat() | pd.concat([s1, s2, s3])  #默认情况下，concat按照行叠加 | 轴向连接函数，沿着指定轴将多个对象堆叠到一起 |
|  |  | pd.merge() | pd.merge(newstu,card, how='left', left_on='学号', right_on='ID') | 按照给定列连接两张表中数据 |
|  |  | dataframe.sort_values() | stu.sort_values(by='成绩', ascending=False) | 按照给定列排序 |
|  |  | Series.sort_values() | members.sort_values(ascending=False) | Series对象排序 |
|  |  | dataframe.rank() | stu['成绩'].rank(method='min', ascending=False) | 按照指定轴给出每个数据排名 |
|  |  |  |  |  |
|  | 5) 统计分析 |  |  |  |
|  |  | sr.value_counts() |  | Series各取值出现的频数 |
|  |  | sr.unique() |  | Series出现的值 |
|  |  | sr.describe() | stu[['身高','体重','成绩']].describe() | 返回基本统计量和分位数 |
|  |  | sr1.corr(sr2) | stu['身高'].corr( stu['体重'] ) | sr1与sr2的相关系数 |
|  |  | df.corr() | stu[['身高','体重','成绩'] ].corr() | df各列的相关系数 |
|  |  | df.count() |  | 统计每列数据个数 |
|  |  | df.max()、df.min() |  | 最大值和最小值 |
|  |  | df.idxmax()、df.idxmin() |  | 最大值、最小值对应的索引 |
|  |  | df.sum() |  | 按行或列求和 |
|  |  | df.mean()、df.median() | stu['成绩'].mean() | 计算均值、中位数 |
|  |  | df.quantile() | tu['月生活费'].quantile( [.25, .75] ) | 计算给定的四分位数 |
|  |  | df.var()、df.std() |  | 计算方差、标准差 |
|  |  | df.mode() |  | 计算众数 |
|  |  | df.cumsum() |  | 从0开始向前累加各元素 |
|  |  | df.cov() | stu[['身高','体重','成绩'] ].cov() | 计算协方差矩阵 |
|  |  | pd.crosstab(df[col1],df[col2]) | pd.crosstab( stu['性别'], stu['月生活费']) | pandas函数，交叉表，计算分组的频率 |
|  |  | dataframe.groupby() | grouped = stu.groupby(['性别', '年龄']) | 按照指定索引将数据划分为多个组 |
|  |  | grouped.aggregate() | grouped.aggregate( {'身高':np.mean, '月生活费':np.max } ) | 按照给定统计方法分组统计 |

## Matplotlib Drawing

|  | 引用模块 | 函数/属性名 | 实例 | 说明 |
| --- | --- | --- | --- | --- |
|  | import matplotlib.pyplot as plt |  |  |  |
|  | 1）pandas绘图 |  |  |  |
|  |  | dataframe.plot() | data.plot(title='2010~2016 GDP',LineWidth=2, marker='o', linestyle='dashed',color='r', grid=True,alpha=0.9,use_index=True,yticks=[3.5,4.0,4.5,5.0,5.5,6.0,6.5,7.0,7.5])<br>#b---blue   c---cyan  g---green    k----black m---magenta r---red  w---white    y----yellow<br>#'  ‘‐'     实线   '‐‐'   破折线  '‐.'    点划线   ‘ :’   虚线    ‘*’ 星性<br># 'o'     实心圈标记  'v'  倒三角标记   's' 实心方形标记   'p'实心五角标记 | pandas绘制图形 |
|  |  | dataframe.plot.scatter() | stdata.plot.scatter(x='Height',y='Weight',title='Students Body Shape', marker='*',grid=True, xlim=[150,200], ylim=[40,80], label='(Height,Weight)') | pandas绘制散点图 |
|  |  | pd.plotting.scatter_matrix() | pd.plotting.scatter_matrix(data,diagonal='kde',color='k') | 绘制散点图矩阵 |
|  |  | dataframe.boxplot() | df1.boxplot(by='Gender',figsize=(6,6)) | 绘制箱须图 |
|  |  | (series/dataframe).plot() | s.plot(kind='bar', ax=axes[0], color='b', alpha=0.7)<br>s.plot(kind='barh', ax=axes[1], color='y', alpha=0.7)<br>df.plot(kind='barh', ax=axes[1], stacked=True, alpha=0.5)<br>s.plot(kind='pie', figsize=(6,6), title='Party size') <br>Series.plot(kind=’hist’,bins=6,normed=True) | 绘制各类图<br>绘制(堆积)柱状图、绘制饼图、脂肪图 |
|  |  |  | x | x轴数据，默认值为None |
|  |  |  | y | y轴数据，默认值为None |
|  |  |  | kind | 绘图类型。‘line’：折线图，默认值；‘bar’：垂直柱状图； ‘barh’：水平柱状图； ‘hist’-直方图； ‘box’-箱线图； ‘kde’-Kernel核密度估计图； ‘density’：-与‘kde’相同； ‘pie’：饼图； ‘scatter’：散点图 |
|  |  |  | title | 图形标题，字符串 |
|  |  |  | color | 画笔颜色。用颜色缩写如’r’、’b’，或RGB值，如’#CECECE’。主要颜色缩写：b-blue c-cyan g-green k-black m-magenta r-red  w-white y-yellow |
|  |  |  | grid | 图形是否有网格，默认值为None |
|  |  |  | fontsize | 坐标轴（包括x轴和y轴）刻度的字体大小。整数，默认值为None |
|  |  |  | alpha | 图表的透明度，0~1之间，图表的透明度，值越大颜色越深 |
|  |  |  | use_index | 默认为True，用索引做x轴刻度 |
|  |  |  | linewidth | 绘图线宽 |
|  |  |  | linestyle | 绘图线型。'‐'实线 '‐‐'破折线 '‐.'点划线 ‘:’ 虚线 |
|  |  |  | marker | 标记风格。’.’点 ‘,’像素（极小点）’o’实心圈 ‘v’倒三角 ‘^’上三角 ‘>’右三角 ‘<’左三角 ‘1’下花三角 ‘2’上花三角 ‘3’左花三角 ‘4’右花三角 ‘s’实心方形 ‘p’实心五角 ‘*’星形 ‘h’’/’’H’竖/横六边形 ‘\|’垂直线 ‘+’十字 ‘x’x ’D’菱形 ‘d’瘦菱形 |
|  |  |  |  |  |
|  | 2）Matplotlib绘图 |  |  |  |
|  |  | plt.figure() | fig = plt.figure(figsize=(8,4)) #figsize参数指定绘图区域的宽度和高度，英寸 | 创建一个绘图对象 |
|  |  | plt.plot() | plt.plot(x, y, 'o-', color='green', linewidth=2.0) | 绘制线性图 |
|  |  | plt.xlabel()、plt.ylabel() | plt.xlabel(‘时间(s)’, fontproperties='SimHei', fontsize=15)<br>plt.ylabel(‘幅度(mV)’, fontproperties='SimHei', fontsize=15) | 设置当前x轴、y轴的标签 |
|  |  | plt.title() | plt.title('Figure 1') | 设置标题 |
|  |  | plt.xticks()、plt.yticks() | plt.xticks(range(0,7),('2010','2011','2012','2013','2014','2015','2016')) | 设置当前x轴、y轴刻度位置的标签和值 |
|  |  | plt.legend() | plt.legend(loc=‘best’, fontsize=20) | 添加图例 |
|  |  | plt.axis() | plt.axis([0, 6, 0, 1.8]) | 设置x, y坐标轴最小最大取值范围 |
|  |  | plt.xlim()、plt.ylim() | plt.xlim([0, 5*np.pi/3])、plt.ylim([0, 5*np.pi/3]) | 设置当前x轴、y轴取值范围 |
|  |  | plt.text() | plt.text(1.8,7.5,'GDP keeps booming!',fontsize='larger') | 添加注解文字 |
|  |  | plt.annotate() | plt.annotate('turning point',xy=(1,7.8),xytext=(0.5,7.5), arrowprops=dict(arrowstyle='->')) | 添加注释 |
|  |  | plt.grid() | plt.grid(True) | 打开或者关闭坐标网格 |
|  |  | plt.figure().add_subplot() | ax1=fig.add_subplot(2,1,1) | 创建子图 |
|  |  | figure.savefig()/fig.savefig() | fig.savefig('2010-2012GDP.jpg',dpi=400,bbox_inches='tight') | 保存图形 |
|  |  | plt.scatter() | plt.scatter(x1, x2) | 绘制单张散点图 |
|  |  | plt.show() | plt.show() | 显示并关闭绘图 |
|  |  |  |  |  |
|  |  |  |  |  |

## Scikit-learn

|  | 引用模块 | 函数/属性名 | 实例 | 说明 |
| --- | --- | --- | --- | --- |
|  | 1) 预处理 |  |  |  |
|  |  | data.values.astype() | X = data.iloc[ :, 0:5 ].values.astype(float)<br>y = data.iloc[ :, 5].values.astype(int) | 从DataFrame获取ndarray |
|  | from sklearn import model_selection | train_test_split() | X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.35, random_state=1) | 按比例随机划分训练集、测试集 |
|  | from sklearn import preprocessing | scale() | X_scale = preprocessing.scale(X) | 将数值型数据标准化处理 |
|  |  |  |  |  |
|  | 2) 初始化、训练模型，预测 |  |  |  |
|  | from sklearn import tree | DecisionTreeClassifier() | clf = tree.DecisionTreeClassifier() | 初始化决策树模型 |
|  | from sklearn import svm | SVC() | clf = svm.SVC(kernel='rbf', gamma=0.6, C = 1.0) | 初始化支持向量机模型 |
|  | from sklearn.linear_model import LinearRegression | LinearRegression() | linreg = LinearRegression() | 初始化线性回归模型 |
|  |  |  | linreg.intercept_, linreg.coef_ | 线性回归模型参数 |
|  | from sklearn.cluster import KMeans | KMeans() | kmeans = KMeans(n_clusters=3) | KMeans模型初始化 |
|  | from sklearn.neural_network import MLPClassifier | MLPClassifier() | mlp = MLPClassifier(solver='lbfgs',alpha=1e-5,hidden_layer_sizes=(5, 5), random_state=1) | 神经网络模型初始化 |
|  |  |  |  |  |
|  |  | model.fit() | clf.fit(X, y)   <br>kmeans.fit(X) | 有监督学习，输入X，y<br>无监督学习，输入X |
|  |  | model.predict() | print("预期销售：",load_linreg.predict(new_X) ) | 使用模型预测 |
|  |  | model.score() | decision_score = linreg.score(X, y) <br>predict_score =linregTr.score(X_test,y_test) | 计算回归函数的决定系数<br>计算分类器的正确率 |
|  |  |  |  |  |
|  | 3) 评估模型性能 |  |  |  |
|  | from sklearn import metrics |  |  |  |
|  |  | mean_squared_error() | test_err = metrics.mean_squared_error(y_test, y_test_pred) | 计算均方误差 |
|  |  | confusion_matrix() | metrics.confusion_matrix(y, predicted_y) | 计算混淆矩阵 |
|  |  | classification_report() | metrics.classification_report(y, predicted_y) | 生成分类性能报告 |
|  |  | adjusted_rand_score() | metrics.adjusted_rand_score(y, kmeans.labels_) | 计算兰德指数 |
|  |  | silhouette_score() | metrics.silhouette_score( X,kmeans.labels_,metric='euclidean' ) | 计算轮廓系数 |
|  |  |  |  |  |
|  | 4）保存、加载模型 |  |  |  |
|  | from sklearn.externals import joblib | dump() | joblib.dump(linreg, 'linreg.pkl') | 将模型保存至文件 |
|  |  | load() | load_linreg = joblib.load('linreg.pkl') | 从文件读取模型 |

## Text Processing

|  | 引用模块 | 函数/属性名 | 实例 | 说明 |
| --- | --- | --- | --- | --- |
|  | 1) 分词、词性标注 |  |  |  |
|  | import jieba | jieba.cut() | jieba.lcut("2018年世界杯小组赛")<br>#sentence：待分词的字符串；cut_all：是否采用全模式；HMM：是否使用 HMM 模型。 | 分词，返回可迭代的generator。支持精确模式和全模式 |
|  |  | jieba.cut_for_search() | #sentence：待分词的字符串；HMM：是否使用 HMM 模型。 | 分词，返回可迭代的 generator。该方法为搜索引擎模式，适合用于建立搜索引擎构建倒排索引，粒度比较细 |
|  |  | jieba.lcut() | jieba.lcut("2018年世界杯小组赛", cut_all = True) | 与cut函数类似，直接返回词列表 |
|  |  | jieba.lcut_for_search() | jieba.lcut_for_search("2018年世界杯小组赛") | 与cut_for_search函数类似，直接返回词列表 |
|  | import jieba.posseg as pseg | pseg.cut | words = pseg.cut("2018年世界杯小组赛") | 分词同时标注词性 |
|  |  |  |  |  |
|  |  |  |  |  |
|  | 2）特征提取 |  |  |  |
|  | from sklearn.feature_extraction.text import CountVectorizer | CountVectorizer() | cv = CountVectorizer() | 词袋模型初始化 |
|  |  | cv.fit_transform() | cv_fit=cv.fit_transform(split_corpus) | 生成词袋向量 |
|  | from sklearn.feature_extraction.text import TfidfTransformer | TfidfTransformer() | tfidf_transformer = TfidfTransformer() | TFIDF转换器初始化 |
|  |  | tfidf_transformer.fit_transform() | tfidf_fit = tfidf_transformer.fit_transform(cv_fit) | 将词袋向量转换为TFIDF向量 |
|  | from sklearn.feature_extraction.text import TfidfVectorizer | TfidfVectorizer() | tfidf = TfidfVectorizer(token_pattern=r"(?u)\b\w+\b") | 初始化TFIDF模型 |
|  |  | tfidf.fit_transform | tfidf_fit=tfidf.fit_transform(split_corpus) | 生成TFIDF向量 |

## Graphic Processing

|  | 引用模块 | 函数/属性名 | 实例 | 说明 |
| --- | --- | --- | --- | --- |
|  | 1) 图形处理 |  |  |  |
|  | from skimage import io | io.imread() | robot = io.imread("data/Robot.jpg") | 从文件中读取图像数据 |
|  |  | img.shape | robot.shape | 图像像素和颜色字节数 |
|  |  | io.imshow() | io.imshow(robot) | 显示图像 |
|  |  | io.show() |  | 显示 |
|  |  | io.imsave() | io.imsave('data/RobotHead.jpg', head) | 将图像数据保存到文件 |
|  |  |  |  |  |
|  | 2) 深度神经网络库keras |  |  |  |
|  | from keras.models import Sequential | Sequential() | model = Sequential() | 序贯模型初始化 |
|  | from keras.layers import Dense | Dense() | model.add(Dense(units=16, input_dim=4)) | 创建Dense层 |
|  | from keras.layers import Activation | Activation() | model.add(Activation('relu')) | 创建Activation层 |
|  | from keras.layers import Dropout | Dropout() | model.add(Dropout(0.25))  #随机断开25%的连接 | 创建Dropout层 |
|  | from keras.layers import Conv2D | Conv2D() | model.add(Conv2D(32, (3, 3), padding='same', <br> input_shape=x_train.shape[1:])) | 创建Conv2D层 |
|  | from keras.layers import MaxPooling2D | MaxPooling2D() | model.add(MaxPooling2D(pool_size=(2, 2))) | 创建MaxPooling2D层 |
|  | from keras.layers import Flattern | Flattern() | model.add(Flatten()) | 创建Flattern层 |
|  |  | model.compile() | model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=["accuracy"]) | 模型编译 |
|  |  |  | scores = model.evaluate(x_test, y_test, verbose=1) | 评估模型性能 |

## Series and Speech Data

| 列1 | 列2 | 列3 | 列4 | 列5 |
| --- | --- | --- | --- | --- |
|  | 引用模块 | 函数/属性名 | 实例 | 说明 |
|  | 1) ARIMA算法 |  |  |  |
|  | from statsmodels.graphics.tsaplots import plot_acf | plot_acf() | plot_acf(data) | 绘制自相关图 |
|  |  | plot_pacf() | plot_pacf(D_data) | 绘制偏自相关图 |
|  | from statsmodels.stats.diagnostic import acorr_ljungbox | acorr_ljungbox() | acorr_ljungbox(data['股价'], lags=1) | 白噪声-检验，纯随机性检验 |
|  | from statsmodels.tsa.stattools import adfuller as ADF | ADF() | ADF(data['股价']) | ADF检验，自相关性检验 |
|  | from statsmodels.tsa.arima_model import ARIMA | ARIMA().fit() | model = ARIMA(data, (p,1,q)).fit() | 输入数据，建立ARIMA模型 |
|  |  | model.aic | model.aic | 计算模型AIC信息准则 |
|  |  | model.summary2() | model.summary2() | 给出模型的分析报告 |
|  |  | model.forecast(5) | model.forecast(5) | 使用模型预测 |
|  |  |  |  |  |
|  | 2）语音识别 |  |  |  |
|  | from aip import AipSpeech | AipSpeech() | client = AipSpeech(APP_ID, API_KEY, SECRET_KEY) | 语音识别模型初始化 |
|  |  | client.asr() | result = aipSpeech.asr(get_file_content(file_name), 'wav', 16000, {'dev_ip': '1536'}) | 识别语音文件 |

